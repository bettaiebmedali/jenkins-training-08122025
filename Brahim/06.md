# TP 6 : Conversion d’un Job Freestyle en Pipeline Jenkins (Jenkinsfile)

## Objectif
Analyser des jobs freestyle existants pour les convertir en un **unique Jenkinsfile** déclaratif qui orchestre :
- récupération du code,
- analyse statique (flake8),
- tests unitaires (pytest),
- build & push d’une image Docker.

Le pipeline doit intégrer :
- gestion des erreurs,
- parallélisation,
- conservation des logs et artifacts,
- utilisation sécurisée des credentials Jenkins.

---

## Prérequis
- Jenkins opérationnel et accès administrateur/éditeur pour créer pipelines et credentials.
- Repo GitHub contenant l’application Python et ses tests.
- Image Dockerfile à la racine du repo (ou adapter le chemin).
- Credentials Jenkins configurés :
  - **docker-hub-creds** — type *Username with password* (username = Docker ID, password = token).
  - (optionnel) **git-credentials** — si le dépôt est privé.

---

## Stratégie & améliorations
- **Paralléliser** l’analyse statique et l’exécution des tests pour gagner du temps.
- **Archiver** les rapports (flake8 output, pytest junit xml, coverage HTML, artefact image metadata).
- **Gestion d’erreurs** : chaque étape critique capture l’erreur et la signale proprement ; néanmoins, on peut laisser des étapes non critiques *unstable* au lieu de stopper tout le pipeline.
- **Sécurité** : utilisation de `withCredentials` pour Docker login.
- **Visibilité** : logs explicites + usage de `junit` pour que Jenkins affiche les résultats de tests.

---

## Jenkinsfile (déclaratif)

```groovy
pipeline {
  agent any

  environment {
    // Variables globales (modifiable)
    APP_NAME = 'my-python-app'
    IMAGE_NAME = "${env.DOCKER_LOGIN ?: 'your-docker-id'}/${APP_NAME}"
    ARTIFACT_DIR = 'artifacts'
  }

  options {
    // Garder un historique de console raisonnable
    timestamps()
    buildDiscarder(logRotator(numToKeepStr: '30'))
  }

  stages {

    stage('Checkout') {
      steps {
        script {
          echo "Cloning repository..."
          checkout scm
        }
      }
    }

    stage('Prepare') {
      steps {
        script {
          sh '''
            python3 --version || true
            python3 -m pip install --user virtualenv || true
            rm -rf ${ARTIFACT_DIR} || true
            mkdir -p ${ARTIFACT_DIR}
          '''
        }
      }
    }

    stage('Lint & Test (parallel)') {
      parallel {
        stage('Static Analysis - flake8') {
          steps {
            script {
              echo "Running flake8..."
              // Installer flake8 si besoin et générer un rapport
              sh '''
                python3 -m pip install --user flake8 || true
                ~/.local/bin/flake8 . --exit-zero --format=default > ${ARTIFACT_DIR}/flake8.txt || true
                echo "Flake8 finished, output -> ${ARTIFACT_DIR}/flake8.txt"
              '''
            }
            // Archive the flake8 output for inspection
            archiveArtifacts artifacts: "${ARTIFACT_DIR}/flake8.txt", allowEmptyArchive: false
          }
        }

        stage('Unit Tests - pytest') {
          steps {
            script {
              echo "Running pytest..."
              sh '''
                python3 -m pip install --user pytest pytest-cov || true
                # run tests and produce junit xml + coverage xml
                ~/.local/bin/pytest -q --junitxml=${ARTIFACT_DIR}/pytest-junit.xml --cov=./ --cov-report=xml:${ARTIFACT_DIR}/coverage.xml || true
              '''
            }
            // Publish test results (so Jenkins parses them)
            junit allowEmptyResults: false, testResults: "${ARTIFACT_DIR}/pytest-junit.xml"
            // Archive coverage + junit xml
            archiveArtifacts artifacts: "${ARTIFACT_DIR}/pytest-junit.xml, ${ARTIFACT_DIR}/coverage.xml", allowEmptyArchive: false
          }
        }
      } // end parallel
    } // end stage Lint & Test

    stage('Build package') {
      steps {
        script {
          echo "Packaging application (ex: sdist or creating deployable files)..."
          sh '''
            # Exemple : créer un tar.gz de l'app (adapter selon projet)
            tar -czf ${ARTIFACT_DIR}/${APP_NAME}-${BUILD_NUMBER}.tar.gz . || true
          '''
        }
        archiveArtifacts artifacts: "${ARTIFACT_DIR}/${APP_NAME}-${BUILD_NUMBER}.tar.gz", fingerprint: true
      }
    }

    stage('Build Docker image') {
      steps {
        script {
          // Build image locally (ne push pas encore)
          echo "Building Docker image ${IMAGE_NAME}:${BUILD_NUMBER}"
          sh '''
            docker build -t ${IMAGE_NAME}:${BUILD_NUMBER} .
            docker image inspect ${IMAGE_NAME}:${BUILD_NUMBER} > ${ARTIFACT_DIR}/image-${BUILD_NUMBER}.json || true
          '''
          archiveArtifacts artifacts: "${ARTIFACT_DIR}/image-${BUILD_NUMBER}.json", fingerprint: true
        }
      }
    }

    stage('Push Docker image') {
      steps {
        script {
          // Use credentials securely to login and push
          withCredentials([usernamePassword(credentialsId: 'docker-hub-creds', usernameVariable: 'DOCKER_LOGIN', passwordVariable: 'DOCKER_PASS')]) {
            sh '''
              echo "Logging into Docker Hub as ${DOCKER_LOGIN}"
              echo "$DOCKER_PASS" | docker login --username "$DOCKER_LOGIN" --password-stdin
              docker push ${DOCKER_LOGIN}/${APP_NAME}:${BUILD_NUMBER}
            '''
          }
        }
      }
    }
  } // end stages

  post {
    always {
      script {
        echo "Post actions : archiving logs, printing summary..."
        // S'assurer que les artifacts de base sont présents
        sh 'ls -la ${ARTIFACT_DIR} || true'
      }
      // Archive console log as artifact (optionnel)
      archiveArtifacts artifacts: "${ARTIFACT_DIR}/**/*", allowEmptyArchive: true
    }

    success {
      echo "Pipeline terminé avec succès — Image poussée : ${IMAGE_NAME}:${BUILD_NUMBER}"
      // Notification possible (email, Slack...) — à ajouter via plugins/steps
    }

    unstable {
      echo "Pipeline marqué unstable — vérifier les rapports"
    }

    failure {
      echo "Pipeline échoué — récupération des logs pour diagnostic"
      // On peut, par ex., envoyer notification ou exporter des informations
      sh 'echo "Build failed at $(date)" > ${ARTIFACT_DIR}/failure-info.txt || true'
      archiveArtifacts artifacts: "${ARTIFACT_DIR}/failure-info.txt", allowEmptyArchive: true
    }
  }
}
``` 
# Remarques d'implémentation et bonnes pratiques

Ne pas stocker de secrets en clair : créez docker-hub-creds dans Jenkins Credentials (type Username with password). Adaptez credentialsId si différent.

Tests & lint : les commandes --exit-zero ou || true sont utilisées pour ne pas interrompre la branche parallèle — mais on publie les résultats via junit et artifacts pour inspection ; si vous préférez arrêter le pipeline sur erreur, supprimez || true et laissez l'étape échouer.

Parallélisation : on exécute lint et tests en parallèle pour réduire le temps global.

Artifacts : tout fichier utile (rapports, archives, inspection d'image) est archivé afin d'assurer traçabilité.

Robustesse : utiliser post pour gérer notifications et récupération après échec.

Extensibilité : on peut ajouter des étapes de déploiement (k8s, serveur), des scans de sécurité (Snyk, Trivy) ou des contrôles de qualité (SonarQube) suivant le besoin.

# Validation & tests

Pousser ce Jenkinsfile à la racine du repo GitHub.

Créer/mettre à jour le job pipeline Jenkins pour pointer sur le repo/branch.

Lancer un build :

Vérifier que : flake8 output, pytest junit xml et coverage.xml sont archivés.

Vérifier que l’image Docker est construite et poussée (regarder artifacts et Docker Hub).

Comparer avec l’implémentation freestyle initiale : mesurez temps d’exécution, lisibilité et résilience.

# Débrief / Points d’amélioration possibles

Ajouter caching Docker layers et optimiser docker build (multi-stage).

Ajouter scans de sécurité (Trivy) et policy gates avant push en production.

Centraliser notifications (Slack/Teams/email) dans post pour alerter l’équipe.

Externaliser certaines étapes dans des bibliothèques partagées (Shared Libraries) pour réutilisabilité.