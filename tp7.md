# üöÄ TP5 ‚Äî CI/CD Complet : Docker local + Kubernetes (Jenkins v2.528.1+)

> Objectif : construire un pipeline Jenkins complet qui **construit une image Docker**, **ex√©cute localement un conteneur pour v√©rification**, **scanne l‚Äôimage**, **pousse l‚Äôimage** sur un registry (Docker Hub), puis **d√©ploie** sur un **cluster Kubernetes**. Le pipeline prend en charge rollback, notifications et bonnes pratiques de s√©curit√©.

---

## üìå Pr√©-requis

### Infrastructure & outils
- Jenkins **v2.528.1+** avec acc√®s Docker (soit Jenkins sur une machine avec Docker install√©, soit agents Docker).  
- Docker Engine install√© sur l'agent qui ex√©cute la phase locale.  
- Acc√®s √† un **registry** (Docker Hub, ECR, GHCR...) et identifiants (username/password or token).  
- Un **cluster Kubernetes** accessible depuis Jenkins (kubeconfig, ou via `kubectl` + credentials).  
- `kubectl` et (optionnel) `helm` install√©s sur l‚Äôagent Jenkins qui ex√©cute les √©tapes Kubernetes.  
- Plugins Jenkins : `Pipeline`, `Docker Pipeline`, `Kubernetes CLI Plugin` (ou `Kubernetes`), `Credentials Binding`, `AnsiColor` (optionnel), `Email Extension`/`Slack Notification` (optionnel).

### Credentials Jenkins √† cr√©er
- **docker_hub** ‚Äî *Username with password* (ou token) pour pousser l‚Äôimage.  
- **kubeconfig** ‚Äî *Secret file / Kubernetes config* (type: `Secret file` or `Kubernetes config`) ; alternative : `kube-creds` via `usernamePassword` + API.  
- **registry_scanner** (facultatif) ‚Äî token pour scanner (Trivy/Snyk), si tu utilises un service externe.

> Place ces credentials dans **G√©rer Jenkins ‚Üí Identifiants ‚Üí System ‚Üí (global)** avec les IDs ci-dessus.

---

## üß≠ Architecture propos√©e du pipeline

1. Checkout repo (Jenkinsfile + code)
2. Build image Docker (tag : `repo:version`)
3. Run image locally (sanity smoke-test)
4. Scan image (Trivy local)
5. Push image vers registry (Docker Hub)
6. Deploy to Kubernetes (manifest / Helm) on a specified environment (DEV/TEST/PROD)
7. Post actions : notifications, cleanup, rollback si besoin

---

## üìÅ Structure recommand√©e du d√©p√¥t Git

```
my-app/
‚îú‚îÄ‚îÄ app.py
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ charts/                  # si utilisation Helm
‚îÇ   ‚îî‚îÄ‚îÄ my-app/
‚îÇ       ‚îî‚îÄ‚îÄ Chart.yaml
‚îú‚îÄ‚îÄ k8s/
‚îÇ   ‚îú‚îÄ‚îÄ deployment.yaml
‚îÇ   ‚îî‚îÄ‚îÄ service.yaml
‚îú‚îÄ‚îÄ Jenkinsfile
‚îú‚îÄ‚îÄ .jenkins/
‚îÇ   ‚îî‚îÄ‚îÄ shared_lib.groovy    # (optionnel) fonctions partag√©es
‚îî‚îÄ‚îÄ .env
```

---

## üîê Gestion des secrets (bonnes pratiques)
- Ne stocke **jamais** kubeconfig ou tokens dans le repo. Utilise les **Credentials Jenkins**.
- Pr√©f√®re **tokens** plut√¥t que mots de passe utilisateur. Active la rotation r√©guli√®re.
- Utilise **withCredentials** pour exposer temporairement les secrets pendant les √©tapes shell.
- Masque les secrets dans les logs (plugin Mask Passwords / Credentials Binding).

---

## ‚úÖ Jenkinsfile complet (multistage, compatible Declarative Pipeline)

> Ce Jenkinsfile assume que les credentials `docker_hub` (username/password) et `kubeconfig` (file) existent dans Jenkins.
> Adapte les valeurs `registry`, `imageName` et chemins k8s selon ton projet.

```groovy
pipeline {
  agent any

  environment {
    REGISTRY = "docker.io/mydockeruser"     // adapter
    IMAGE_NAME = "my-app"
    // VERSION peut venir d'un tag Git ou d'un param√®tre
  }

  parameters {
    string(name: 'VERSION', defaultValue: '0.1.0-${BUILD_NUMBER}', description: 'Version / Tag de l‚Äôimage')
    choice(name: 'TARGET_ENV', choices: ['DEV','TEST','PROD'], description: 'Environnement de d√©ploiement')
    booleanParam(name: 'SKIP_SCAN', defaultValue: false, description: 'Passer l‚Äôanalyse de s√©curit√©?')
    booleanParam(name: 'RUN_LOCAL', defaultValue: true, description: 'D√©marrer l‚Äôimage localement pour tests rapides?')
    booleanParam(name: 'FORCE_DEPLOY', defaultValue: false, description: 'Forcer le d√©ploiement m√™me si scan signale vuln√©rabilit√©s?')
  }

  stages {
    stage('Checkout') {
      steps {
        checkout scm
      }
    }

    stage('Build Docker image') {
      steps {
        script {
          IMAGE_TAG = "${env.REGISTRY}/${env.IMAGE_NAME}:${params.VERSION}"
          echo "Build image ${IMAGE_TAG}"
        }
        sh "docker build -t ${IMAGE_TAG} ."
      }
    }

    stage('Run local smoke-test') {
      when { expression { return params.RUN_LOCAL } }
      steps {
        script {
          def containerName = "jenkins_test_${env.BUILD_NUMBER}"
          sh """
            docker run -d --name ${containerName} -p 8080:8080 ${IMAGE_TAG} || true
            sleep 2
            # Ex√©cuter un test simple (adapter l'URL/healthcheck)
            curl --silent --fail http://localhost:8080/health || (docker logs ${containerName} && exit 1)
            docker stop ${containerName} || true
            docker rm ${containerName} || true
          """
        }
      }
    }

    stage('Scan image (Trivy)') {
      when { expression { return !params.SKIP_SCAN } }
      steps {
        script {
          // Utilise trivy s'il est install√© sur l'agent; sinon saute cette √©tape
          sh """
            if command -v trivy >/dev/null 2>&1; then
              trivy image --exit-code 1 --severity HIGH,CRITICAL ${IMAGE_TAG} || true
            else
              echo "Trivy non disponible, skip scan"
            fi
          """
        }
      }
    }

    stage('Push to registry') {
      steps {
        withCredentials([usernamePassword(credentialsId: 'docker_hub', usernameVariable: 'DOCKER_USER', passwordVariable: 'DOCKER_PASS')]) {
          sh """
            echo "$DOCKER_PASS" | docker login -u "$DOCKER_USER" --password-stdin
            docker push ${IMAGE_TAG}
            docker logout
          """
        }
      }
    }

    stage('Deploy to Kubernetes') {
      steps {
        withCredentials([file(credentialsId: 'kubeconfig', variable: 'KUBECONFIG_FILE')]) {
          # place le kubeconfig dans un fichier temporaire et exporte KUBECONFIG
          sh """
            export KUBECONFIG=${KUBECONFIG_FILE}
            # Affiche le contexte pour v√©rification
            kubectl config current-context
            # Remplace l'image dans les manifests (ex: k8s/deployment.yaml templating)
            sed -e "s|IMAGE_PLACEHOLDER|${IMAGE_TAG}|g" k8s/deployment.yaml > k8s/deployment_for_jenkins.yaml
            kubectl apply -f k8s/deployment_for_jenkins.yaml -n ${params.TARGET_ENV,,} || true
            # Rollout status
            kubectl -n ${params.TARGET_ENV,,} rollout status deployment/my-app --timeout=120s || (kubectl -n ${params.TARGET_ENV,,} get pods -o wide && exit 1)
          """
        }
      }
    }

    stage('Post-deploy verification') {
      steps {
        sh """
          # Exemple de v√©rification simple : hit le service via kubectl port-forward (ou utiliser Ingress/Service URL)
          echo "V√©rification post d√©ploiement (ex√©cut√©e depuis agent)"
        """
      }
    }
  } // stages

  post {
    success {
      echo "‚úÖ Pipeline termin√© avec succ√®s : ${IMAGE_TAG}"
      // notifications optionnelles (Slack, Email)
    }
    unstable {
      echo "‚ö†Ô∏è Pipeline instable"
    }
    failure {
      echo "üî• Pipeline √©chou√©"
      // Option de rollback basique : d√©ployer l'image pr√©c√©dente
      script {
        if (params.FORCE_DEPLOY == false) {
          echo "Trigger rollback manual or automatic depending on policy"
        }
      }
    }
    always {
      // nettoyage local d'images temporaires si voulu
      sh 'docker image prune -f || true'
    }
  }
}
```

---

## üîÅ Rollback basique (strat√©gies)

1. **Rollback manuel via UI** : redeployer un build pr√©c√©dent depuis Jenkins (Build ‚Üí Rebuild).  
2. **Rollback automatique** : conserver le tag pr√©c√©dent (`previousTag`) et `kubectl set image deployment/my-app my-app=${previousTag}` en cas d‚Äô√©chec.  
3. **Blue/Green or Canary** : impl√©mentation avanc√©e avec service switch, helm charts ou Istio/Argo Rollouts.

Exemple simplifi√© pour rollback automatique (snippet √† int√©grer dans `post.failure`):
```groovy
// pseudo-code
def previous = sh(returnStdout:true, script: "kubectl -n ${env.TARGET_ENV} get deployment my-app -o=jsonpath='{.spec.template.spec.containers[0].image}'").trim()
sh "kubectl -n ${env.TARGET_ENV} set image deployment/my-app my-app=${previous}"
```

---

## üîé V√©rifications & Tests recommand√©s

- S‚Äôassurer que `kubectl` fonctionne depuis l‚Äôagent : `kubectl get nodes`  
- V√©rifier les droits du kubeconfig (namespace, RBAC) : l‚Äôutilisateur doit pouvoir `apply`, `get`, `rollout status`.  
- Tester le push docker localement : `docker login && docker push`  
- Installer `trivy` sur l‚Äôagent pour scans locaux : `sudo apt-get install trivy` ou utiliser l‚Äôimage trivy via docker run.

---

## üõ°Ô∏è S√©curit√© & Best Practices

- Ne pas ex√©cuter des builds Docker en tant que root sur des agents partag√©s. Pr√©f√®re agents d√©di√©s ou conteneurs Docker-in-Docker s√©curis√©s.  
- Utiliser **Image signing** et **Content Trust** pour garantir provenance des images.  
- Scanner les images automatiquement et d√©finir une politique d‚Äôacceptation (ex: bloquer sur vuln√©rabilit√©s Critiques).  
- Configurer des quotas et limitations (CPU/m√©moire) pour pods et namespaces.  
- Auditer les actions Jenkins (Audit Trail plugin).

---

## üßæ Conseils de debugging

- Si d√©ploiement √©choue ‚Üí `kubectl -n <env> describe pod <pod>` et `kubectl logs pod/<pod>`  
- Si push √©choue ‚Üí v√©rifier `docker login` et quotas registry.  
- Si build √©choue ‚Üí inspecter Dockerfile et contexte de build (fichiers .dockerignore).

---

## ‚úÖ R√©capitulatif et prochaines √©tapes

Ce TP5 te permet de :
- Construire, tester localement, scanner et pousser des images Docker.  
- D√©ployer automatiquement sur Kubernetes en ciblant des environnements distincts.  
- Mettre en place des strat√©gies de rollback et notifications.

üîú Propositions d‚Äôextensions :  
- Impl√©menter **Blue/Green** ou **Canary** (Istio/Argo Rollouts)  
- Int√©grer **Politiques de s√©curit√©** (OPA/Gatekeeper)  
- D√©ploiements GitOps (ArgoCD)  

---
